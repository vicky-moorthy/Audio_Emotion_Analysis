{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOBhzWpYaqKBpTVQ2kL+awx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zcqzvsoQJBXw","executionInfo":{"status":"ok","timestamp":1686669563703,"user_tz":-330,"elapsed":34318,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"002e953e-cc08-4ec4-ae5b-0400ec65b407"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","libasound2-dev is already the newest version (1.2.2-2.1ubuntu2.5).\n","ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n","Suggested packages:\n","  portaudio19-doc\n","The following NEW packages will be installed:\n","  libportaudio2 libportaudiocpp0 portaudio19-dev\n","0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n","Need to get 188 kB of archives.\n","After this operation, 926 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudio2 amd64 19.6.0-1build1 [65.4 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu focal/universe amd64 libportaudiocpp0 amd64 19.6.0-1build1 [16.1 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu focal/universe amd64 portaudio19-dev amd64 19.6.0-1build1 [106 kB]\n","Fetched 188 kB in 0s (456 kB/s)\n","Selecting previously unselected package libportaudio2:amd64.\n","(Reading database ... 122541 files and directories currently installed.)\n","Preparing to unpack .../libportaudio2_19.6.0-1build1_amd64.deb ...\n","Unpacking libportaudio2:amd64 (19.6.0-1build1) ...\n","Selecting previously unselected package libportaudiocpp0:amd64.\n","Preparing to unpack .../libportaudiocpp0_19.6.0-1build1_amd64.deb ...\n","Unpacking libportaudiocpp0:amd64 (19.6.0-1build1) ...\n","Selecting previously unselected package portaudio19-dev:amd64.\n","Preparing to unpack .../portaudio19-dev_19.6.0-1build1_amd64.deb ...\n","Unpacking portaudio19-dev:amd64 (19.6.0-1build1) ...\n","Setting up libportaudio2:amd64 (19.6.0-1build1) ...\n","Setting up libportaudiocpp0:amd64 (19.6.0-1build1) ...\n","Setting up portaudio19-dev:amd64 (19.6.0-1build1) ...\n","Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting PyAudio\n","  Downloading PyAudio-0.2.13.tar.gz (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: PyAudio\n","  Building wheel for PyAudio (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for PyAudio: filename=PyAudio-0.2.13-cp310-cp310-linux_x86_64.whl size=69029 sha256=b7e385b0f8cacde31a6a4ca18bf6ad864f9ed86f9a0845689a7d113165cb6c4b\n","  Stored in directory: /root/.cache/pip/wheels/14/f1/c2/d102b4765a82c5a7bb273998dca7e4a53fc58e9a1a516fda81\n","Successfully built PyAudio\n","Installing collected packages: PyAudio\n","Successfully installed PyAudio-0.2.13\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pydub\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Installing collected packages: pydub\n","Successfully installed pydub-0.25.1\n"]}],"source":["!apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg\n","!pip install PyAudio\n","!pip install pydub"]},{"cell_type":"code","source":["!mkdir models\n","!mkdir working\n","!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/audio.hdf5 -O models/audio.hdf5\n","!wget http://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/testfile.json -O models/testfile.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w7E92NR0JN6-","executionInfo":{"status":"ok","timestamp":1686669568145,"user_tz":-330,"elapsed":1685,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"ce453d12-92d0-4f80-cfd3-771d6ee19563"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-13 15:19:26--  http://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/audio.hdf5\n","Resolving github.com (github.com)... 140.82.112.3\n","Connecting to github.com (github.com)|140.82.112.3|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/audio.hdf5 [following]\n","--2023-06-13 15:19:26--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/audio.hdf5\n","Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://github.com/DeivisDervinis/Speech-Emotion-Analyzer/raw/main/colab/models/audio.hdf5 [following]\n","--2023-06-13 15:19:26--  https://github.com/DeivisDervinis/Speech-Emotion-Analyzer/raw/main/colab/models/audio.hdf5\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/DeivisDervinis/Speech-Emotion-Analyzer/main/colab/models/audio.hdf5 [following]\n","--2023-06-13 15:19:27--  https://raw.githubusercontent.com/DeivisDervinis/Speech-Emotion-Analyzer/main/colab/models/audio.hdf5\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 5368560 (5.1M) [application/octet-stream]\n","Saving to: ‘models/audio.hdf5’\n","\n","models/audio.hdf5   100%[===================>]   5.12M  --.-KB/s    in 0.08s   \n","\n","2023-06-13 15:19:27 (65.5 MB/s) - ‘models/audio.hdf5’ saved [5368560/5368560]\n","\n","URL transformed to HTTPS due to an HSTS policy\n","--2023-06-13 15:19:27--  https://github.com/DeivisDervinis/EAPDA/raw/main/colab/models/testfile.json\n","Resolving github.com (github.com)... 140.82.114.3\n","Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://github.com/DeivisDervinis/Speech-Emotion-Analyzer/raw/main/colab/models/testfile.json [following]\n","--2023-06-13 15:19:27--  https://github.com/DeivisDervinis/Speech-Emotion-Analyzer/raw/main/colab/models/testfile.json\n","Reusing existing connection to github.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://raw.githubusercontent.com/DeivisDervinis/Speech-Emotion-Analyzer/main/colab/models/testfile.json [following]\n","--2023-06-13 15:19:28--  https://raw.githubusercontent.com/DeivisDervinis/Speech-Emotion-Analyzer/main/colab/models/testfile.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 336 [text/plain]\n","Saving to: ‘models/testfile.json’\n","\n","models/testfile.jso 100%[===================>]     336  --.-KB/s    in 0s      \n","\n","2023-06-13 15:19:28 (21.8 MB/s) - ‘models/testfile.json’ saved [336/336]\n","\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()\n","for fn in uploaded.keys():\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","uploaded_file_name = list(uploaded.keys())[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351},"id":"e8No2o43Jb83","executionInfo":{"status":"ok","timestamp":1686032938837,"user_tz":-330,"elapsed":75599,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"3cfdfc64-01b2-44c4-cd93-4ac67c9da81a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-dd33a1b9-dae2-4170-ba52-42450482665e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-dd33a1b9-dae2-4170-ba52-42450482665e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving KL_su11.wav to KL_su11.wav\n","Saving KL_su12.wav to KL_su12.wav\n","Saving KL_su14.wav to KL_su14.wav\n","Saving KL_su15.wav to KL_su15.wav\n","Saving KL_sa10.wav to KL_sa10.wav\n","Saving KL_sa11.wav to KL_sa11.wav\n","User uploaded file \"KL_su11.wav\" with length 177684 bytes\n","User uploaded file \"KL_su12.wav\" with length 344398 bytes\n","User uploaded file \"KL_su14.wav\" with length 464648 bytes\n","User uploaded file \"KL_su15.wav\" with length 516572 bytes\n","User uploaded file \"KL_sa10.wav\" with length 366394 bytes\n","User uploaded file \"KL_sa11.wav\" with length 487960 bytes\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bE2WXQwbZLgp","executionInfo":{"status":"ok","timestamp":1686032991232,"user_tz":-330,"elapsed":20276,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"32ed1a24-223a-4801-b3c0-cba975a32d8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import time\n","import os\n","import numpy as np\n","import pyaudio\n","import wave\n","import librosa\n","from scipy.stats import zscore\n","import tensorflow as tf\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, Activation, TimeDistributed\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten\n","from tensorflow.keras.layers import LSTM"],"metadata":{"id":"YzVaJjEAJovR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class speechEmotionRecognition:\n","\n","    ###\n","    ##Voice recording function\n","    ##\n","\n","    def __init__(self, subdir_model=None):\n","\n","        # Load prediction model\n","        if subdir_model is not None:\n","            self._model = self.build_model()\n","            self._model.load_weights(subdir_model)\n","\n","        # Emotion encoding\n","        self._emotion = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Neutral', 5:'Sad', 6:'Surprise'}\n","\n","\n","    ### Computing Mel-Spectrogram\n","    def mel_spectrogram(self, y, sr=16000, n_fft=512, win_length=256, hop_length=128, window='hamming', n_mels=128, fmax=4000):\n","\n","        # Compute spectogram\n","        mel_spect = np.abs(librosa.stft(y, n_fft=n_fft, window=window, win_length=win_length, hop_length=hop_length)) ** 2\n","\n","        # Compute mel spectrogram\n","        mel_spect = librosa.feature.melspectrogram(S=mel_spect, sr=sr, n_mels=n_mels, fmax=fmax)\n","\n","        # Compute log-mel spectrogram\n","        mel_spect = librosa.power_to_db(mel_spect, ref=np.max)\n","\n","        return np.asarray(mel_spect)\n","\n","\n","\n","    # Audio framing\n","    def frame(self, y, win_step=64, win_size=128):\n","\n","        # Number of frames\n","        nb_frames = 1 + int((y.shape[2] - win_size) / win_step)\n","\n","        # Framming\n","        frames = np.zeros((y.shape[0], nb_frames, y.shape[1], win_size)).astype(np.float16)\n","        for t in range(nb_frames):\n","            frames[:,t,:,:] = np.copy(y[:,:,(t * win_step):(t * win_step + win_size)]).astype(np.float16)\n","\n","        return frames\n","\n","\n","    # Builds TDCNN\n","    def build_model(self):\n","\n","        # Clear Keras session\n","        K.clear_session()\n","\n","        # Define input\n","        input_y = Input(shape=(3, 128, 128, 1), name='Input_MELSPECT')\n","\n","        # First LFLB (local feature learning block)\n","        y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_1_MELSPECT')(input_y)\n","        y = TimeDistributed(BatchNormalization(), name='BatchNorm_1_MELSPECT')(y)\n","        y = TimeDistributed(Activation('elu'), name='Activ_1_MELSPECT')(y)\n","        y = TimeDistributed(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'), name='MaxPool_1_MELSPECT')(y)\n","        y = TimeDistributed(Dropout(0.2), name='Drop_1_MELSPECT')(y)\n","\n","        # Second LFLB (local feature learning block)\n","        y = TimeDistributed(Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_2_MELSPECT')(y)\n","        y = TimeDistributed(BatchNormalization(), name='BatchNorm_2_MELSPECT')(y)\n","        y = TimeDistributed(Activation('elu'), name='Activ_2_MELSPECT')(y)\n","        y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_2_MELSPECT')(y)\n","        y = TimeDistributed(Dropout(0.2), name='Drop_2_MELSPECT')(y)\n","\n","        # Third LFLB (local feature learning block)\n","        y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_3_MELSPECT')(y)\n","        y = TimeDistributed(BatchNormalization(), name='BatchNorm_3_MELSPECT')(y)\n","        y = TimeDistributed(Activation('elu'), name='Activ_3_MELSPECT')(y)\n","        y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_3_MELSPECT')(y)\n","        y = TimeDistributed(Dropout(0.2), name='Drop_3_MELSPECT')(y)\n","\n","        # Fourth LFLB (local feature learning block)\n","        y = TimeDistributed(Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same'), name='Conv_4_MELSPECT')(y)\n","        y = TimeDistributed(BatchNormalization(), name='BatchNorm_4_MELSPECT')(y)\n","        y = TimeDistributed(Activation('elu'), name='Activ_4_MELSPECT')(y)\n","        y = TimeDistributed(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'), name='MaxPool_4_MELSPECT')(y)\n","        y = TimeDistributed(Dropout(0.2), name='Drop_4_MELSPECT')(y)\n","\n","        # Flat\n","        y = TimeDistributed(Flatten(), name='Flat_MELSPECT')(y)\n","\n","        # LSTM layer\n","        y = LSTM(256, return_sequences=False, dropout=0.2, name='LSTM_1')(y)\n","\n","        # Fully connected\n","        y = Dense(7, activation='softmax', name='FC')(y)\n","\n","        # Build final model\n","        model = Model(inputs=input_y, outputs=y)\n","\n","        return model\n","\n","\n","\n","    # Predict speech emotion over time\n","    def predict_emotion_from_file(self, filename, chunk_step=16000, chunk_size=40000, predict_proba=False, sample_rate=16000):\n","\n","        # Read audio file\n","        y, sr = librosa.core.load(filename, sr=sample_rate, offset=0.5)\n","        # Split audio signals into chunks\n","        chunks = self.frame(y.reshape(1, 1, -1), chunk_step, chunk_size)\n","\n","        # Reshape chunks\n","        chunks = chunks.reshape(chunks.shape[1],chunks.shape[-1])\n","\n","        # Z-normalization\n","        y = np.asarray(list(map(zscore, chunks)))\n","\n","        # Compute mel spectrogram\n","        mel_spect = np.asarray(list(map(self.mel_spectrogram, y)))\n","\n","        # Time distributed Framing\n","        mel_spect_ts = self.frame(mel_spect)\n","\n","        # Build X for time distributed CNN\n","        X = mel_spect_ts.reshape(mel_spect_ts.shape[0],\n","                                    mel_spect_ts.shape[1],\n","                                    mel_spect_ts.shape[2],\n","                                    mel_spect_ts.shape[3],\n","                                    1)\n","\n","        # Predict emotion\n","        if predict_proba is True:\n","            predict = self._model.predict(X)\n","        else:\n","            predict = np.argmax(self._model.predict(X), axis=1)\n","            predict = [self._emotion.get(emotion) for emotion in predict]\n","\n","\n","        # Clear Keras session\n","        K.clear_session()\n","\n","        # Predict timestamp\n","        timestamp = np.concatenate([[chunk_size], np.ones((len(predict) - 1)) * chunk_step]).cumsum()\n","        timestamp = np.round(timestamp / sample_rate)\n","\n","        return [predict, timestamp]\n","\n","\n","\n","    #Export emotions\n","    def prediction_to_csv(self, predictions, filename, mode='w'):\n","\n","        # Write emotion in filename\n","        with open(filename, mode) as f:\n","            if mode == 'w':\n","                f.write(\"EMOTIONS\"+'\\n')\n","            for emotion in predictions:\n","                f.write(str(emotion)+'\\n')\n","            f.close()"],"metadata":{"id":"dxwDorUaJrof"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from collections import Counter\n","\n"," #Function that finds the most common occuring emotion\n","def find_state_emotion(listOfEmotions):\n","\n","  count = Counter(listOfEmotions)\n","  max_val = max(count.values())\n","  return sorted(key for key, value in count.items() if value == max_val)"],"metadata":{"id":"14_zhHQAKeEk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","import math\n","from pydub import AudioSegment\n","# Set model sub directory path\n","model_sub_dir = os.path.join('models', 'audio.hdf5')\n","emotion = {0:'Angry', 1:'Disgust', 2:'Fear', 3:'Happy', 4:'Neutral', 5:'Sad', 6:'Surprise'}\n","\n","# Initialize SER object\n","SER = speechEmotionRecognition(model_sub_dir)\n","\n","# Create an empty segment emotion list to store emotions\n","segmentEmoList = []\n","\n","# Create a list of timestamps\n","timestampList = []\n","timestampCounter = 6\n","\n","\n","# Create an empty final emotion list for tracking emotions through segments\n","finalEmoList = []\n","\n","# List of state flags\n","stateFlagList = [0,0,0,0,0,0,0]\n","\n","# Create an emotion found flag to check if the final emotion was found or not\n","isFirstStateFound = False\n","isFirstStateEncountered = False\n","\n","# Create an empty string for final emotion\n","finalEmotion = \"\"\n","stateEmotion = \"\"\n","\n","# Set the name of the audio file\n","#audio_file_name = os.path.join(\"data\",\"joined_sound_7.wav\")\n","audio_file_name = uploaded_file_name\n","\n","# Sets the duration of audio\n","audio_duration = math.floor(librosa.get_duration(filename=audio_file_name))\n","\n","# Pritns the duration of the audio\n","print(\"The duration of audio is: \" +str(audio_duration))\n","# Starting slice and end slice values\n","n = 0\n","nSpan = 3\n","\n","# List of sliced segments\n","listOfSegNames = []\n","\n","for i in range(0, (audio_duration + 1) - nSpan):\n","    t1 = n * 1000\n","    t2 = (n + nSpan) * 1000\n","\n","    # Select audio file to segment\n","    oldAudio = AudioSegment.from_wav(audio_file_name)\n","\n","    # Create a segment of 3 seconds from old audio file\n","    newAudio = oldAudio[t1:t2]\n","\n","    # Save new segment name\n","    seg_name = \"working/seg_\" + str(n) + \"_\" +str((n+nSpan)) +\".wav\"\n","\n","    # Append segment name to a list for later use\n","    listOfSegNames.append(seg_name)\n","\n","    # Export segment to its own individual file\n","    newAudio.export(seg_name, format=\"wav\")\n","\n","    # Slide the selected second slider by one\n","    n += 1\n","\n","# Run prediction for each segment\n","for k in range(0, len(listOfSegNames)):\n","    # Select the segment from the list of saved segment names\n","    rec_sub_dir = listOfSegNames[k]\n","\n","    # Predict emotion in voice at each time step\n","    step = 1 # in sec\n","    sample_rate = 16000 # in kHz\n","    emotions, timestamp = SER.predict_emotion_from_file(rec_sub_dir, chunk_step=step*sample_rate)\n","\n","    # Append emotion of the segment to a list\n","    maxValEmo = max(set(emotions), key=emotions.count)\n","    segmentEmoList.append(maxValEmo)\n","\n","    # Check states after the initial state\n","    if isFirstStateFound == True:\n","      timestampCounter += 1\n","\n","      # Determine the state of the emotion\n","      stateEmotion = max(set(emotions), key=emotions.count)\n","\n","      # Find the index for the determined emotion\n","      stateIndex = list(emotion.keys())[list(emotion.values()).index(stateEmotion)]\n","\n","      # Increment by 1 for the state that appears\n","      stateFlagList[stateIndex] += 1\n","\n","      # Check if any of the states (Emotions) occurs 3 times\n","      if stateFlagList[stateIndex] == 3:\n","        # Get the emotion by the index\n","        stateEmotion = emotion.get(stateIndex)\n","\n","        # Append the emotion to the final emotion list\n","        finalEmoList.append([stateEmotion])\n","\n","        timestampList.append(timestampCounter)\n","\n","        # Reset the state (emotion) occurance list to zero\n","        stateFlagList = [0,0,0,0,0,0,0]\n","        timestampCounter = 0\n","\n","    # Set the initial state emotion\n","    if len(segmentEmoList) > 2 and isFirstStateFound == False:\n","      # Call function to determine emotion\n","      firstState = find_state_emotion(segmentEmoList)\n","      #print(firstState)\n","      if len(firstState) == 1:\n","        # Add the segment emotion to the list\n","        finalEmoList.append(firstState)\n","        timestampCounter += 2\n","        timestampList.append(timestampCounter)\n","        timestampCounter = 0\n","        isFirstStateFound = True\n","      else:\n","        timestampCounter += 1\n","\n","\n","# Prints for debugging\n","print(segmentEmoList)\n","print(timestampList)\n","\n","if sum(timestampList) != audio_duration:\n","  timestampList[-1] = timestampList[-1] + (audio_duration - sum(timestampList))\n","\n","print(timestampList)\n","# Create an empty list to store unhashedList\n","unhashedList = []\n","\n","# Unhashes a list for readability\n","for item in finalEmoList:\n","  unhashedList.append(item[0])\n","\n","# Check if there is a majority for the segments\n","print(unhashedList)\n","return_emotion = find_state_emotion(unhashedList)\n","print(return_emotion)\n","\n","# If there is no majority therefore the emotion is neutral\n","if len(return_emotion) != 1:\n","  print(\"Majority doesn't win\")\n","  print(\"The emotion is: Neutral\")\n","else:\n","  # If there is a majority then print the emotion\n","  print(\"Majority wins\")\n","  print(\"The emotion is: \" + str(return_emotion[0]))\n","  del timestampList[:]\n","  timestampList.append(audio_duration)\n","\n","# Code for removing the segments\n","for segment in listOfSegNames:\n","  !rm $segment\n","print(\"Previous segments removed\")\n","\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"8-rj56VIKj9Y","executionInfo":{"status":"error","timestamp":1686033642858,"user_tz":-330,"elapsed":1050,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"a05d789f-ba5b-4037-8d3d-d80488c16dba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The duration of audio is: 2\n","[]\n","[]\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-24-f1a320a4c548>:38: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n","\tThis alias will be removed in version 1.0.\n","  audio_duration = math.floor(librosa.get_duration(filename=audio_file_name))\n"]},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-f1a320a4c548>\u001b[0m in \u001b[0;36m<cell line: 132>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestampList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0maudio_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0mtimestampList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maudio_duration\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestampList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestampList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"oEazxW2fbA8G","executionInfo":{"status":"error","timestamp":1686033601771,"user_tz":-330,"elapsed":415,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"6d36171d-98c8-4c0e-faa5-278105d5b549"},"execution_count":null,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-23d36c75783b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestampList\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0maudio_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtimestampList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestampList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maudio_duration\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestampList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestampList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create an empty list to store unhashedList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","colorDict = {'Angry':\"#ff5954\",'Disgust':\"#6eff69\", 'Fear':\"#b152ff\", 'Happy': '#fff673', 'Neutral':'#ccccc8', 'Sad':'#5c8dff', 'Surprise':'#ffb663'}\n","colorList = []\n","\n","df = pd.DataFrame({}, index=[0])\n","counter = 0\n","for item in segmentEmoList:\n","  df.insert(counter, item, 1, True)\n","  counter += 1\n","  colorList.append(colorDict.get(item))\n","\n","ax = df.plot.barh(stacked=True, color=colorList)\n","\n","\n","ax.figure.set_size_inches(25,6)\n","ax.set_xlabel('Time (in sec)', fontsize=18)\n","ax.set_ylabel('States', fontsize=18)\n","ax.set_yticklabels([])\n","\n","handles, labels = ax.get_legend_handles_labels()\n","by_label = dict(zip(labels, handles))\n","\n","ax.set_title(audio_file_name)\n","ax.legend(by_label.values(), by_label.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"TIc9jNToKvAZ","executionInfo":{"status":"error","timestamp":1686033468836,"user_tz":-330,"elapsed":886,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"32baa489-57d7-41bc-f035-1675313d2368"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-540ce345c498>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mcolorList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolorDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolorList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mbarh\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0mother\u001b[0m \u001b[0maxis\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmeasured\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \"\"\"\n\u001b[0;32m-> 1245\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"barh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPlotAccessor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    998\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# no non-numeric frames or series allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no numeric data to plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"]}]},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","colorDict = {'Angry':\"#ff5954\",'Disgust':\"#6eff69\", 'Fear':\"#b152ff\", 'Happy': '#fff673', 'Neutral':'#ccccc8', 'Sad':'#5c8dff', 'Surprise':'#ffb663'}\n","colorList = []\n","\n","df = pd.DataFrame({}, index=[0])\n","counter = 0\n","\n","if len(unhashedList) == len(timestampList):\n","  for index in unhashedList:\n","    df.insert(counter, index, timestampList[counter], True)\n","    counter += 1\n","    colorList.append(colorDict.get(index))\n","else:\n","  df.insert(0, return_emotion[0], timestampList[0], True)\n","  colorList.append(colorDict.get(return_emotion[0]))\n","\n","ax = df.plot.barh(stacked=True, color=colorList)\n","\n","\n","ax.figure.set_size_inches(25,6)\n","ax.set_xlabel('Time (in sec)', fontsize=18)\n","ax.set_ylabel('States', fontsize=18)\n","ax.set_yticklabels([])\n","\n","handles, labels = ax.get_legend_handles_labels()\n","by_label = dict(zip(labels, handles))\n","\n","ax.set_title(audio_file_name)\n","ax.legend(by_label.values(), by_label.keys())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"wbR5AV__Yc4P","executionInfo":{"status":"error","timestamp":1686033501249,"user_tz":-330,"elapsed":8,"user":{"displayName":"vicky moorthy","userId":"05146142558285051153"}},"outputId":"25ce9110-9403-4540-8e2d-e43d42958411"},"execution_count":null,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f28840545535>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mcolorList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolorDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_emotion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstacked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolorList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36mbarh\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m   1243\u001b[0m         \u001b[0mother\u001b[0m \u001b[0maxis\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmeasured\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \"\"\"\n\u001b[0;32m-> 1245\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"barh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mPlotAccessor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    998\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1000\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mplot_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m     \u001b[0m__call__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_matplotlib/__init__.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ax\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left_ax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mplot_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPLOT_CLASSES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mplot_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_plot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_subplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/plotting/_matplotlib/core.py\u001b[0m in \u001b[0;36m_compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# no non-numeric frames or series allowed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no numeric data to plot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_ndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"]}]},{"cell_type":"code","source":["segmentEmoDuration = {'Angry':0,'Disgust':0, 'Fear':0, 'Happy': 0, 'Neutral':0, 'Sad':0, 'Surprise':0}\n","\n","counter = audio_duration\n","labels = []\n","sizes = []\n","\n","index = 0\n","\n","for item in unhashedList:\n","  if item in segmentEmoDuration:\n","    segmentEmoDuration[item] = timestampList[index]\n","    index += 1\n","\n","for emotion in segmentEmoDuration:\n","  if segmentEmoDuration.get(emotion) > 0:\n","    accuracy = (segmentEmoDuration.get(emotion) / counter) * 100\n","    labels.append(emotion)\n","    sizes.append(accuracy)\n","    print(\"Accuracy of \" +emotion +\": \" +str(accuracy) +\"%\")\n","\n","fig2, ax2 = plt.subplots()\n","ax2.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n","ax2.axis('equal')\n","plt.show()"],"metadata":{"id":"Z6wJJOpfYgsp"},"execution_count":null,"outputs":[]}]}